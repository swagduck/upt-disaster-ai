import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
import joblib
import os

class GuardianAI:
    def __init__(self):
        self.model_path = "app/upt_engine/guardian_model.pkl"
        self.scaler = StandardScaler()
        # S·ª≠ d·ª•ng Random Forest: M·∫°nh m·∫Ω, ch·ªëng overfitting t·ªët cho d·ªØ li·ªáu th·∫£m h·ªça
        self.model = RandomForestRegressor(n_estimators=100, random_state=42)
        self.is_trained = False
        
        # D·ªØ li·ªáu m·∫´u kh·ªüi t·∫°o (Seed Data) ƒë·ªÉ AI kh√¥ng b·ªã l·ªói khi ch∆∞a c√≥ d·ªØ li·ªáu th·∫≠t
        # Feature: [Lat, Lon, Energy, Anomaly]
        self.X_buffer = [
            [35.0, 139.0, 0.8, 0.5],  # Japan Quake (M·∫´u)
            [-5.0, 120.0, 0.6, 0.7],  # Indonesia Volcano (M·∫´u)
            [37.0, -122.0, 0.4, 0.2], # USA Minor (M·∫´u)
            [15.0, 108.0, 0.2, 0.1],  # Vietnam Minor (M·∫´u)
        ]
        # Label: [Risk_Score] (0.0 -> 1.0)
        self.y_buffer = [0.9, 0.7, 0.3, 0.1] 
        
        self._initial_train()

    def _initial_train(self):
        """Hu·∫•n luy·ªán s∆° b·ªô khi kh·ªüi ƒë·ªông server"""
        try:
            X = np.array(self.X_buffer)
            y = np.array(self.y_buffer)
            self.scaler.fit(X)
            self.model.fit(self.scaler.transform(X), y)
            self.is_trained = True
            print("üß† [NEURAL CORE] AI Model initialized and active.")
        except Exception as e:
            print(f"‚ö†Ô∏è [NEURAL CORE] Init failed: {e}")

    def learn(self, sensors_data):
        """H·ªçc t·ª´ d·ªØ li·ªáu th·ªùi gian th·ª±c m·ªõi nh·∫•t (Online Learning)"""
        new_events = 0
        for s in sensors_data:
            # Ch·ªâ h·ªçc t·ª´ c√°c s·ª± ki·ªán c√≥ c·∫•u tr√∫c h·ª£p l·ªá t·ª´ DisasterService
            # C·∫ßn ƒë·∫£m b·∫£o s l√† dict v√† c√≥ c√°c key c·∫ßn thi·∫øt
            if isinstance(s, dict) and 'lat' in s and 'lon' in s:
                energy = s.get('energy_level', 0.5)
                anomaly = s.get('anomaly_score', 0.5)
                
                feature = [s['lat'], s['lon'], energy, anomaly]
                
                # Gi·∫£ ƒë·ªãnh Risk = Energy * 0.7 + Anomaly * 0.3 (Heuristic Labeling)
                # Trong th·ª±c t·∫ø, label n√†y n√™n ƒë·∫øn t·ª´ d·ªØ li·ªáu thi·ªát h·∫°i l·ªãch s·ª≠
                label = min(1.0, energy * 0.7 + anomaly * 0.3)
                
                self.X_buffer.append(feature)
                self.y_buffer.append(label)
                new_events += 1
        
        # Gi·ªõi h·∫°n b·ªô nh·ªõ ƒë·ªám (Rolling Window) ƒë·ªÉ tr√°nh tr√†n RAM
        max_buffer = 2000
        if len(self.X_buffer) > max_buffer:
            self.X_buffer = self.X_buffer[-max_buffer:]
            self.y_buffer = self.y_buffer[-max_buffer:]
            
        # Retrain nhanh
        if new_events > 0:
            X = np.array(self.X_buffer)
            y = np.array(self.y_buffer)
            self.model.fit(self.scaler.transform(X), y)
            
        return len(self.X_buffer)

    def predict_risk(self, lat, lon, energy, anomaly):
        """D·ª± ƒëo√°n r·ªßi ro cho m·ªôt t·ªça ƒë·ªô b·∫•t k·ª≥"""
        if not self.is_trained: return 0.0
        
        try:
            input_data = np.array([[lat, lon, energy, anomaly]])
            scaled_input = self.scaler.transform(input_data)
            prediction = self.model.predict(scaled_input)[0]
            return float(max(0.0, min(1.0, prediction)))
        except Exception as e:
            print(f"Prediction Error: {e}")
            return 0.0

# Singleton Instance (D√πng chung cho c·∫£ App)
guardian_brain = GuardianAI()