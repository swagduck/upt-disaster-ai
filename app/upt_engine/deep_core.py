import numpy as np
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from collections import deque
from app.core.database import Database

class DeepGuardian:
    def __init__(self):
        self.model_path = "app/upt_engine/guardian_lstm.keras"
        self.scaler = MinMaxScaler(feature_range=(0, 1))
        self.look_back = 5 # AI nh√¨n l·∫°i 5 b∆∞·ªõc th·ªùi gian
        self.is_trained = False
        self.model = None
        
        # --- BUFFER B·ªò NH·ªö TH·ª∞C T·∫æ ---
        self.realtime_buffer = deque(maxlen=self.look_back)
        
        # Ki·ªÉm tra GPU
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            print(f"üöÄ [DEEP CORE] NVIDIA GPU Active: {len(gpus)} device(s).")
        else:
            print("‚ö†Ô∏è [DEEP CORE] Running on CPU Mode.")

        self._build_brain()
        
        # Kh·ªüi ƒë·ªông: Train t·ª´ DB
        if Database.db is not None:
            print("üß† [DEEP CORE] Loading Memory Patterns...")
            self.train_from_memory()
        
    def _build_brain(self):
        """LSTM Architecture"""
        self.model = tf.keras.models.Sequential()
        self.model.add(tf.keras.layers.Input(shape=(self.look_back, 5)))
        
        self.model.add(tf.keras.layers.LSTM(units=64, return_sequences=True))
        self.model.add(tf.keras.layers.Dropout(0.2))
        
        self.model.add(tf.keras.layers.LSTM(units=32))
        self.model.add(tf.keras.layers.Dropout(0.2))
        
        self.model.add(tf.keras.layers.Dense(1, activation='sigmoid'))
        
        self.model.compile(optimizer='adam', loss='binary_crossentropy')

    def train_from_memory(self):
        """Train l·∫°i model t·ª´ l·ªãch s·ª≠ MongoDB"""
        col = Database.get_collection("raw_logs")
        if col is None: return 0
        
        try:
            logs = list(col.find().sort("timestamp", 1).limit(1000))
        except: return 0
        
        if len(logs) < self.look_back + 10: return 0
        
        data = []
        for log in logs:
            sensors = log.get('sensors_data', [])
            avg_energy = np.mean([s.get('energy_level', 0) for s in sensors]) if sensors else 0
            avg_anomaly = np.mean([s.get('anomaly_score', 0) for s in sensors]) if sensors else 0
            max_mag = log.get('max_magnitude', 0)
            data.append([avg_energy, avg_anomaly, max_mag, 0.5, 0.5])

        dataset = np.array(data)
        self.scaler.fit(dataset)
        dataset_scaled = self.scaler.transform(dataset)
        
        X, y = [], []
        for i in range(self.look_back, len(dataset_scaled)):
            X.append(dataset_scaled[i-self.look_back:i, :])
            y.append(dataset_scaled[i, 2]) 
            
        X, y = np.array(X), np.array(y)
        
        self.model.fit(X, y, epochs=3, batch_size=4, verbose=0)
        self.is_trained = True
        return len(X)

    # --- üëá B·ªî SUNG QUAN TR·ªåNG: H√ÄM WRAPPER ƒê·ªÇ S·ª¨A L·ªñI API üëá ---
    def learn(self, sensors_data=None):
        """
        H√†m t∆∞∆°ng th√≠ch ng∆∞·ª£c (Backward Compatibility).
        API prediction.py v·∫´n g·ªçi h√†m n√†y. Ch√∫ng ta tr·ªè n√≥ v·ªÅ train_from_memory.
        """
        return self.train_from_memory()
    # ------------------------------------------------------------

    def predict_risk(self, lat, lon, energy, anomaly):
        """D·ª± ƒëo√°n r·ªßi ro d·ª±a tr√™n chu·ªói d·ªØ li·ªáu th·ª±c t·∫ø."""
        current_features = [energy, anomaly, 0.5, 0.5, 0.5]
        self.realtime_buffer.append(current_features)
        
        if len(self.realtime_buffer) < self.look_back:
            return (energy * 0.7 + anomaly * 0.3)
            
        if not self.is_trained:
            return (energy + anomaly) / 2.0

        try:
            raw_seq = np.array(list(self.realtime_buffer))
            seq_scaled = self.scaler.transform(raw_seq)
            input_reshaped = np.reshape(seq_scaled, (1, self.look_back, 5))
            
            prediction = self.model.predict(input_reshaped, verbose=0)
            return float(prediction[0][0])
            
        except Exception as e:
            print(f"LSTM Error: {e}")
            return 0.5

# Singleton
guardian_brain = DeepGuardian()